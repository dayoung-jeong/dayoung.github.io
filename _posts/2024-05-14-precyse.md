---
title: "PRECYSE: Predicting Cybersickness using Transformer for Multimodal Time-Series Sensor Data"
excerpt: '<u><strong>D Jeong</strong></u> and K Han <br> <span style="color: #9370db"><strong>ACM IMWUT (UbiComp 2024)</strong></span> <em>BK CS Conference (IF=3)</em> <br> <a href="https://doi.org/10.1145/3659594" target="_blank" style="background:#576A8F; color:white; padding:2px 8px; border-radius:6px; text-decoration:none; font-size:0.75rem; font-weight:700;">DOI</a> <a href="https://astlyi.s3.ap-northeast-2.amazonaws.com/2024/%5B117%5DPRECYSE.pdf" target="_blank" style="background:#FAB95B; color:white; padding:2px 8px; border-radius:6px; text-decoration:none; font-size:0.75rem; font-weight:700;">PDF</a>'
date: 2024-05-14
categories:
  - HAI
  - Virtual Reality
tags:
  - Cybersickness
  - Time Series
  - Sensor Data
---

<span style="color: #9370db"><strong>ACM IMWUT (UbiComp 2024)</strong></span>

<u><strong>D Jeong</strong></u> and K Han

**Abstract**

Cybersickness, a factor that hinders user immersion in VR, has been the subject of ongoing attempts to predict it using AI. Previous studies have used CNN and LSTM for prediction models and used attention mechanisms and XAI for data analysis, yet none explored a transformer that can better reflect the spatial and temporal characteristics of the data, beneficial for enhancing prediction and feature importance analysis. In this paper, we propose cybersickness prediction models using multimodal time-series sensor data (i.e., eye movement, head movement, and physiological signals) based on a transformer algorithm, considering sensor data pre-processing and multimodal data fusion methods. We constructed the MSCVR dataset consisting of normalized sensor data, spectrogram formatted sensor data, and cybersickness levels collected from 45 participants through a user study. We proposed two methods for embedding multimodal time-series sensor data into the transformer: modality-specific spatial and temporal transformer encoders for normalized sensor data (MS-STTN) and modality-specific spatial-temporal transformer encoder for spectrogram (MS-STTS). MS-STTN yielded the highest performance in the ablation study and the comparison of the existing models. Furthermore, by analyzing the importance of data features, we determined their relevance to cybersickness over time, especially the salience of eye movement features. Our results and insights derived from multimodal time-series sensor data and the transformer model provide a comprehensive understanding of cybersickness and its association with sensor data.

**The Architecture of MS-STTN**

{% include figure image_path="/assets/images/PRECYSE_MS-STTN.png" alt="MS-STTN" caption="The architecture of the modality-specific spatial and temporal transformer encoders for normalized sensor data (MS-STTN). (a) The spatial transformer encoder (STE) learns interaction characteristics between sensor signals. (b) The MS-STTN learns spatial and temporal characteristics for each modality. (c) The temporal transformer encoder (TTE) learns temporal characteristics of sensor data." %}
